{"cells": [{"metadata": {}, "cell_type": "code", "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='r5BTTcJzPtQAjkxLJtj8WDfMtoutEg5MlBOFmYGkUa6m',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.eu.cloud-object-storage.appdomain.cloud')\n\nbucket = 'updateddatasetagesturebasedtoolfo-donotdelete-pr-uqmd8pc2o6fapp'\nobject_key = 'dataset-20221114T173550Z-001.zip'\n\nstreaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from io import BytesIO\nimport zipfile\nunzip=zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\nfile_paths=unzip.namelist()\nfor path in file_paths:\n    unzip.extract(path)", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "\u001b[0m\u001b[01;34mdataset\u001b[0m/  PNT2022TMID35856handgesture.tgz\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Convolution Neural Network\n#Importing tensorflow library\nimport tensorflow as tf\nprint(tf.__version__)\n#Model Creation\nmodel=tf.keras.Sequential([\n                #Conv2D -To extract the essential features\n                #Maxpooling - to compress the image without losing its features\n                #Inupt shape of the image=128*128 pixels\n                #relu - if x>0,return x;else return 0\n                tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(128,128,1)),\n                tf.keras.layers.MaxPooling2D(2,2),\n                tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n                tf.keras.layers.MaxPooling2D(2,2),\n                tf.keras.layers.Conv2D(16,(3,3),activation='relu'),\n                tf.keras.layers.MaxPooling2D(2,2),\n                #Takes the image and coverts it to a linear array-flatten\n                tf.keras.layers.Flatten(),\n                #Hidden layers\n                #softmax-Activation function that predict multinomial probability\n                tf.keras.layers.Dense(512,activation='relu'),#Hidden layer1:512 neurons\n                tf.keras.layers.Dense(6,activation='softmax')#Output layer=No of classifications\n])", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "2.7.2\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen=ImageDataGenerator(rescale=1./255)#Normalisation\n#Preprocessing the Training dataset\ntrain_gen=train_datagen.flow_from_directory(\n    'dataset/train',\n    #Image size:128*128\n    target_size=(128,128),\n    batch_size=198,\n    #Train Dataset has Grayscale images\n    color_mode='grayscale',\n    #Since output has classification class_mode='categorical'\n    class_mode='categorical'\n)", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "Found 2376 images belonging to 6 classes.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Test data preprocessing\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n#Normalisation\nvalid_datagen=ImageDataGenerator(rescale=1./255)\nvalid_gen=valid_datagen.flow_from_directory(\n    'dataset/test',\n    target_size=(128,128),\n    batch_size=10,\n    color_mode='grayscale',\n    class_mode='categorical'\n)", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "Found 30 images belonging to 6 classes.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Categorical crossentropy as output layer has 6 classes\n#Optimiser-to reduce the weights or coefficients of hidden layer\nmodel.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['Accuracy'])", "execution_count": 23, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.summary()", "execution_count": 24, "outputs": [{"output_type": "stream", "text": "Model: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_6 (Conv2D)           (None, 126, 126, 16)      160       \n                                                                 \n max_pooling2d_6 (MaxPooling  (None, 63, 63, 16)       0         \n 2D)                                                             \n                                                                 \n conv2d_7 (Conv2D)           (None, 61, 61, 32)        4640      \n                                                                 \n max_pooling2d_7 (MaxPooling  (None, 30, 30, 32)       0         \n 2D)                                                             \n                                                                 \n conv2d_8 (Conv2D)           (None, 28, 28, 16)        4624      \n                                                                 \n max_pooling2d_8 (MaxPooling  (None, 14, 14, 16)       0         \n 2D)                                                             \n                                                                 \n flatten_2 (Flatten)         (None, 3136)              0         \n                                                                 \n dense_4 (Dense)             (None, 512)               1606144   \n                                                                 \n dense_5 (Dense)             (None, 6)                 3078      \n                                                                 \n=================================================================\nTotal params: 1,618,646\nTrainable params: 1,618,646\nNon-trainable params: 0\n_________________________________________________________________\n", "name": "stdout"}]}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "#Train the model\ntrainmodel=model.fit(\n    train_gen,#Preprocessed Training dataset\n    steps_per_epoch=12,#Total images in training dataset/batch_size of train dataset\n    epochs=2,\n    validation_data=valid_gen,#Preprocessed Test dataset\n    validation_steps=3#Total images in test dataset/batch_size of test dataset\n)", "execution_count": 26, "outputs": [{"output_type": "stream", "text": "Epoch 1/2\n12/12 [==============================] - 17s 1s/step - loss: 0.0478 - Accuracy: 0.9941 - val_loss: 0.3636 - val_Accuracy: 0.9000\nEpoch 2/2\n12/12 [==============================] - 17s 1s/step - loss: 0.0385 - Accuracy: 0.9937 - val_loss: 0.3413 - val_Accuracy: 0.9000\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "model.save('gesture.h5')\nmodel_json=model.to_json()\nwith open(\"model-bw.json\",\"w\") as json_file:\n  json_file.write(model_json)", "execution_count": 27, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 33, "outputs": [{"output_type": "stream", "text": "\u001b[0m\u001b[01;34mdataset\u001b[0m/  gesture.h5  model-bw.json  PNT2022TMID35856handgesture.tgz\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!tar -zcvf PNT2022TMID35856handgesture.tgz gesture.h5", "execution_count": 29, "outputs": [{"output_type": "stream", "text": "gesture.h5\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install watson-machine-learning-client --upgrade", "execution_count": 30, "outputs": [{"output_type": "stream", "text": "Collecting watson-machine-learning-client\n  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 538 kB 25.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\nRequirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\nRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\nInstalling collected packages: watson-machine-learning-client\nSuccessfully installed watson-machine-learning-client-1.0.391\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#https://{instance_ID}.eu-de.secrets-manager.appdomain.cloud\nfrom ibm_watson_machine_learning import APIClient\nwml_credentials={\n                  \"url\":\"https://eu-de.ml.cloud.ibm.com\",\n                  \"apikey\": \"Pr3DmF-RTQXov0Z4-WRezikhExRbHV2PsrDdX-kjPmg7\"\n                }\nclient=APIClient(wml_credentials)", "execution_count": 31, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def guid_from_space_name(client, space_name):\n    space=client.spaces.get_details()\n    return(next(item for item in space['resources'] if item['entity'][\"name\"]==space_name)[\"metadata\"][\"id\"])", "execution_count": 32, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "space_uid=guid_from_space_name(client,'gesturebasedtoolforsterilebrowsingofradiologyimages')\nprint(\"Space UID=\",space_uid)", "execution_count": 34, "outputs": [{"output_type": "stream", "text": "Space UID= d1770620-22c8-4c92-bc67-f356ac6cc203\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space(space_uid)", "execution_count": 35, "outputs": [{"output_type": "execute_result", "execution_count": 35, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.software_specifications.list()", "execution_count": 36, "outputs": [{"output_type": "stream", "text": "-----------------------------  ------------------------------------  ----\nNAME                           ASSET_ID                              TYPE\ndefault_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\nkernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\npytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\nscikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\nspark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\npytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\nai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\nshiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\ntensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\npytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\ntensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\nautoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\nruntime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\nscikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\ndefault_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\npytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\nkernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\npytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\ntensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\nspark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\ntensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\nruntime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\ndo_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\nautoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\ntensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\nkernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\npytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\nspark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\npytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\nspark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\nspark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\nautoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\nxgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\npytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\npytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\ndefault_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\nautoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\nautoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\npmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\nspark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\nxgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\npytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\nautoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\nspark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\nspark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\nautoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\nspss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\ncuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\nruntime-22.2-py3.10-xc         5e8cddff-db4a-5a6a-b8aa-2d4af9864dab  base\nautoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n-----------------------------  ------------------------------------  ----\nNote: Only first 50 records were displayed. To display more use 'limit' parameter.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "software_spec_uid=client.software_specifications.get_uid_by_name(\"tensorflow_rt22.1-py3.9\")\nsoftware_spec_uid", "execution_count": 37, "outputs": [{"output_type": "execute_result", "execution_count": 37, "data": {"text/plain": "'acd9c798-6974-5d2f-a657-ce06e986df4d'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model_details=client.repository.store_model(model=\"PNT2022TMID35856handgesture.tgz\",meta_props={\n    client.repository.ModelMetaNames.NAME:\"gesture\",\n    client.repository.ModelMetaNames.TYPE:\"tensorflow_rt22.1\",\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid})\nmodel_id=client.repository.get_model_id(model_details)", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client.repository.download(model_id, \"hand_gesture-model_new_cloud.tgz\")", "execution_count": 39, "outputs": [{"output_type": "stream", "text": "Successfully saved model content to file: 'hand_gesture-model_new_cloud.tgz'\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 39, "data": {"text/plain": "'/home/wsuser/work/hand_gesture-model_new_cloud.tgz'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 40, "outputs": [{"output_type": "stream", "text": "\u001b[0m\u001b[01;34mdataset\u001b[0m/    hand_gesture-model_new_cloud.tgz  PNT2022TMID35856handgesture.tgz\r\ngesture.h5  model-bw.json\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from tensorflow.python.keras.models import load_model\nmodel_body = load_model('gesture.h5')", "execution_count": 41, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from keras.models import load_model\nfrom keras.preprocessing import image", "execution_count": 42, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model=load_model('gesture.h5')", "execution_count": 43, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='r5BTTcJzPtQAjkxLJtj8WDfMtoutEg5MlBOFmYGkUa6m',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.eu.cloud-object-storage.appdomain.cloud')\n\nbucket = 'updateddatasetagesturebasedtoolfo-donotdelete-pr-uqmd8pc2o6fapp'\nobject_key = 'dataset-20221114T173550Z-001.zip'\n\nstreaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 49, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from io import BytesIO\nimport zipfile\nunzip=zipfile.ZipFile(BytesIO(streaming_body_2.read()),'r')\nfile_paths=unzip.namelist()\nfor path in file_paths:\n    unzip.extract(path)", "execution_count": 50, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimgs=mpimg.imread(path)\nimgplot=plt.imshow(imgs)\nplt.show()", "execution_count": 51, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<Figure size 432x288 with 1 Axes>", "image/png": "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\n"}, "metadata": {"needs_background": "light"}}]}, {"metadata": {}, "cell_type": "code", "source": "img=image.load_img(path,color_mode='grayscale',target_size=(128,128))\n#image to array\nx=image.img_to_array(img)", "execution_count": 52, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "x.shape", "execution_count": 53, "outputs": [{"output_type": "execute_result", "execution_count": 53, "data": {"text/plain": "(128, 128, 1)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\nx=np.expand_dims(x,axis=0)\nx.shape", "execution_count": 54, "outputs": [{"output_type": "execute_result", "execution_count": 54, "data": {"text/plain": "(1, 128, 128, 1)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "pred=np.argmax(model.predict(x),axis=-1)\n#predicting the class\nindex=['0','1','2','3','4','5']", "execution_count": 55, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pred", "execution_count": 56, "outputs": [{"output_type": "execute_result", "execution_count": 56, "data": {"text/plain": "array([0])"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "result=str(index[pred[0]])", "execution_count": 57, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "result", "execution_count": 58, "outputs": [{"output_type": "execute_result", "execution_count": 58, "data": {"text/plain": "'0'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "test_img = []\n\nfor i in range(0,6):\n    for j in range(0,5):\n        path = \"dataset/test/\"+str(i)+\"/\"+str(j)+\".jpg\"\n        img = image.load_img(path,color_mode = \"grayscale\",target_size= (128,128))\n        x = image.img_to_array(img)\n        x = np.expand_dims(x,axis = 0)\n        pred = np.argmax(model.predict(x), axis=-1)\n        test_img.append(pred)\nprint(test_img)", "execution_count": 59, "outputs": [{"output_type": "stream", "text": "[array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([2]), array([2]), array([1]), array([2]), array([2]), array([3]), array([3]), array([3]), array([5]), array([3]), array([4]), array([4]), array([4]), array([4]), array([5]), array([5]), array([5]), array([5]), array([5]), array([5])]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "test_res = []\nindex=['0','1','2','3','4','5']\nfor i in test_img:\n    test_res.append(index[i[0]])\nprint(test_res)", "execution_count": 60, "outputs": [{"output_type": "stream", "text": "['0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '2', '2', '1', '2', '2', '3', '3', '3', '5', '3', '4', '4', '4', '4', '5', '5', '5', '5', '5', '5']\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}