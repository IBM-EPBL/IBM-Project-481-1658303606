{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='r5BTTcJzPtQAjkxLJtj8WDfMtoutEg5MlBOFmYGkUa6m',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.eu.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'updateddatasetagesturebasedtoolfo-donotdelete-pr-uqmd8pc2o6fapp'\n",
    "object_key = 'dataset-20221114T173550Z-001.zip'\n",
    "\n",
    "streaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "unzip=zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\n",
    "file_paths=unzip.namelist()\n",
    "for path in file_paths:\n",
    "    unzip.extract(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdataset\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.2\n"
     ]
    }
   ],
   "source": [
    "#Convolution Neural Network\n",
    "#Importing tensorflow library\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#Model Creation\n",
    "model=tf.keras.Sequential([\n",
    "                #Conv2D -To extract the essential features\n",
    "                #Maxpooling - to compress the image without losing its features\n",
    "                #Inupt shape of the image=128*128 pixels\n",
    "                #relu - if x>0,return x;else return 0\n",
    "                tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(128,128,1)),\n",
    "                tf.keras.layers.MaxPooling2D(2,2),\n",
    "                tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(2,2),\n",
    "                tf.keras.layers.Conv2D(16,(3,3),activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(2,2),\n",
    "                #Takes the image and coverts it to a linear array-flatten\n",
    "                tf.keras.layers.Flatten(),\n",
    "                #Hidden layers\n",
    "                #softmax-Activation function that predict multinomial probability\n",
    "                tf.keras.layers.Dense(512,activation='relu'),#Hidden layer1:512 neurons\n",
    "                tf.keras.layers.Dense(6,activation='softmax')#Output layer=No of classifications\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2376 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255)#Normalisation\n",
    "#Preprocessing the Training dataset\n",
    "train_gen=train_datagen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    #Image size:128*128\n",
    "    target_size=(128,128),\n",
    "    batch_size=198,\n",
    "    #Train Dataset has Grayscale images\n",
    "    color_mode='grayscale',\n",
    "    #Since output has classification class_mode='categorical'\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "#Test data preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#Normalisation\n",
    "valid_datagen=ImageDataGenerator(rescale=1./255)\n",
    "valid_gen=valid_datagen.flow_from_directory(\n",
    "    'dataset/test',\n",
    "    target_size=(128,128),\n",
    "    batch_size=10,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical crossentropy as output layer has 6 classes\n",
    "#Optimiser-to reduce the weights or coefficients of hidden layer\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 126, 126, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 63, 63, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 61, 61, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 30, 30, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 14, 14, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,618,646\n",
      "Trainable params: 1,618,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 1.6598 - Accuracy: 0.2988 - val_loss: 1.2940 - val_Accuracy: 0.5333\n",
      "Epoch 2/17\n",
      "12/12 [==============================] - 25s 2s/step - loss: 1.0772 - Accuracy: 0.6120 - val_loss: 1.3332 - val_Accuracy: 0.4000\n",
      "Epoch 3/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.7170 - Accuracy: 0.7247 - val_loss: 0.6527 - val_Accuracy: 0.7667\n",
      "Epoch 4/17\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.5884 - Accuracy: 0.7715 - val_loss: 0.6410 - val_Accuracy: 0.7333\n",
      "Epoch 5/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.4581 - Accuracy: 0.8304 - val_loss: 0.6164 - val_Accuracy: 0.7000\n",
      "Epoch 6/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.3671 - Accuracy: 0.8754 - val_loss: 0.6048 - val_Accuracy: 0.7000\n",
      "Epoch 7/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.2795 - Accuracy: 0.9179 - val_loss: 0.4531 - val_Accuracy: 0.8000\n",
      "Epoch 8/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.2393 - Accuracy: 0.9242 - val_loss: 0.7577 - val_Accuracy: 0.6333\n",
      "Epoch 9/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.2202 - Accuracy: 0.9230 - val_loss: 0.4227 - val_Accuracy: 0.7333\n",
      "Epoch 10/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.1602 - Accuracy: 0.9554 - val_loss: 0.4835 - val_Accuracy: 0.7333\n",
      "Epoch 11/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.1400 - Accuracy: 0.9621 - val_loss: 0.3144 - val_Accuracy: 0.9000\n",
      "Epoch 12/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.0987 - Accuracy: 0.9785 - val_loss: 0.3224 - val_Accuracy: 0.9000\n",
      "Epoch 13/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.0628 - Accuracy: 0.9912 - val_loss: 0.3950 - val_Accuracy: 0.8667\n",
      "Epoch 14/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.0610 - Accuracy: 0.9899 - val_loss: 0.2909 - val_Accuracy: 0.9000\n",
      "Epoch 15/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.0459 - Accuracy: 0.9933 - val_loss: 0.2637 - val_Accuracy: 0.9667\n",
      "Epoch 16/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.0321 - Accuracy: 0.9975 - val_loss: 0.2892 - val_Accuracy: 0.9667\n",
      "Epoch 17/17\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.0250 - Accuracy: 0.9996 - val_loss: 0.3256 - val_Accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "trainmodel=model.fit(\n",
    "    train_gen,#Preprocessed Training dataset\n",
    "    steps_per_epoch=12,#Total images in training dataset/batch_size of train dataset\n",
    "    epochs=17,\n",
    "    validation_data=valid_gen,#Preprocessed Test dataset\n",
    "    validation_steps=3#Total images in test dataset/batch_size of test dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('gesture.h5')\n",
    "model_json=model.to_json()\n",
    "with open(\"model-bw.json\",\"w\") as json_file:\n",
    "  json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdataset\u001b[0m/  gesture.h5  model-bw.json\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
